{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Learner/Facilitator Guide to Advanced Scikit Learn Training - 6 Dec 2021",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xd92F8fimqm"
      },
      "source": [
        "#Topic 1 Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoIlYGVGpt4t"
      },
      "source": [
        "## Dealing with Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdpskuFREbjm"
      },
      "source": [
        "In the example, we will work with the Melbourne Housing dataset. Our model will use information such as the number of rooms and land size to predict home price.\n",
        "\n",
        "We won't focus on the data loading step. Instead, you can imagine you are at a point where you already have the training and validation data in X_train, X_valid, y_train, and y_valid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMKfWPEpil5T"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv')\n",
        "\n",
        "# Select target\n",
        "y = data.Price\n",
        "\n",
        "# To keep things simple, we'll use only numerical predictors\n",
        "melb_predictors = data.drop(['Price'], axis=1)\n",
        "X = melb_predictors.select_dtypes(exclude=['object'])\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySngZhujFqrN"
      },
      "source": [
        "### Define Function to Measure Quality of Each Approach¶\n",
        "We define a function score_dataset() to compare different approaches to dealing with missing values. This function reports the mean absolute error (MAE) from a random forest model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0GHvsAkkYHg"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function for comparing different approaches\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return mean_absolute_error(y_valid, preds)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFhIPQMNEfjQ"
      },
      "source": [
        "### Score from Approach 1 (Drop Columns with Missing Values)\n",
        "Since we are working with both training and validation sets, we are careful to drop the same columns in both DataFrames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpLrNot_kgfF"
      },
      "source": [
        "# Get names of columns with missing values\n",
        "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
        "\n",
        "# Drop columns in training and validation data\n",
        "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
        "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
        "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmqf9BTkF8HX"
      },
      "source": [
        "### Score from Approach 2 (Imputation)\n",
        "Next, we use SimpleImputer to replace missing values with the mean value along each column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVQV85J8klxX"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Imputation\n",
        "my_imputer = SimpleImputer()\n",
        "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n",
        "imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))\n",
        "\n",
        "# Imputation removed column names; put them back\n",
        "imputed_X_train.columns = X_train.columns\n",
        "imputed_X_valid.columns = X_valid.columns\n",
        "\n",
        "print(\"MAE from Approach 2 (Imputation):\")\n",
        "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkK7o543Gpdl"
      },
      "source": [
        "We see that Approach 2 has lower MAE than Approach 1, so Approach 2 performed better on this dataset.\n",
        "Dropping the columns removes a lot of useful information, and so it makes sense that imputation would perform better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMpV1faamOja"
      },
      "source": [
        "## Categorical Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMSFI2dGLJoC"
      },
      "source": [
        "we will work with the Melbourne Housing dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAixC0SAmRTu"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv')\n",
        "\n",
        "# Separate target from predictors\n",
        "y = data.Price\n",
        "X = data.drop(['Price'], axis=1)\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "# Drop columns with missing values (simplest approach)\n",
        "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
        "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
        "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
        "\n",
        "# \"Cardinality\" means the number of unique values in a column\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
        "                        X_train_full[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "my_cols = low_cardinality_cols + numerical_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rdCjcLpLSyr"
      },
      "source": [
        "We take a peek at the training data with the head() method below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pxby5MhNmcdY"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdlOnBeKLXDT"
      },
      "source": [
        "Next, we obtain a list of all of the categorical variables in the training data.\n",
        "\n",
        "We do this by checking the data type (or dtype) of each column. The object dtype indicates a column has text. For this dataset, the columns with text indicate categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPiM7le0mffc"
      },
      "source": [
        "# Get list of categorical variables\n",
        "s = (X_train.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "\n",
        "print(\"Categorical variables:\")\n",
        "print(object_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myRvnuY2L8b1"
      },
      "source": [
        "### Define Function to Measure Quality of Each Approach¶\n",
        "We define a function score_dataset() to compare different approaches to dealing with missing values. This function reports the mean absolute error (MAE) from a random forest model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7eSi7k4mjNv"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function for comparing different approaches\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return mean_absolute_error(y_valid, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-MRH8OpMFaW"
      },
      "source": [
        "### Approach 1 - Drop Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmYvupLWmm2P"
      },
      "source": [
        "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
        "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
        "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3OjJa1-Mnzw"
      },
      "source": [
        "### Approach 2 - Ordinal Encoding\n",
        "Scikit-learn has a OrdinalEncoder class that can be used to get ordinal encodings. We loop over the categorical variables and apply the ordinal encoder separately to each colum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAy7CjTYmrHR"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Make copy to avoid changing original data \n",
        "label_X_train = X_train.copy()\n",
        "label_X_valid = X_valid.copy()\n",
        "\n",
        "# Apply ordinal encoder to each column with categorical data\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
        "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
        "\n",
        "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
        "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bW5zISGzM3HR"
      },
      "source": [
        "### Approach 3 - One-Hot Encoding\n",
        "We use the OneHotEncoder class from scikit-learn to get one-hot encodings. There are a number of parameters that can be used to customize its behavior.\n",
        "\n",
        "- We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
        "- setting sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
        "\n",
        "To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et_e21ppmwkT"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Apply one-hot encoder to each column with categorical data\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
        "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = X_train.index\n",
        "OH_cols_valid.index = X_valid.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_train = X_train.drop(object_cols, axis=1)\n",
        "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
        "\n",
        "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
        "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkVFNI28VclB"
      },
      "source": [
        "### Activity: Ordinal Encoding and One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-RzghVUWwNZ"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/autos.csv\")\n",
        "\n",
        "# Separate target from predictors\n",
        "X = df.copy()\n",
        "y = X.pop(\"price\")\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "# Drop columns with missing values (simplest approach)\n",
        "cols_with_missing = [col for col in X_train_full.columns if X_train_full[col].isnull().any()] \n",
        "X_train_full.drop(cols_with_missing, axis=1, inplace=True)\n",
        "X_valid_full.drop(cols_with_missing, axis=1, inplace=True)\n",
        "\n",
        "# \"Cardinality\" means the number of unique values in a column\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
        "                        X_train_full[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "my_cols = low_cardinality_cols + numerical_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGljAtqvXKMj"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPm7KTQwVbWM"
      },
      "source": [
        "# Get list of categorical variables\n",
        "s = (X_train.dtypes == 'object')\n",
        "object_cols = list(s[s].index)\n",
        "\n",
        "print(\"Categorical variables:\")\n",
        "print(object_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wci3RCbCWZM0"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Function for comparing different approaches\n",
        "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_valid)\n",
        "    return mean_absolute_error(y_valid, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6XSw4KrXng3"
      },
      "source": [
        "### Approach 1 - Drop Categorical Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnU7gvoGVkY0"
      },
      "source": [
        "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
        "drop_X_valid = X_valid.select_dtypes(exclude=['object'])\n",
        "\n",
        "print(\"MAE from Approach 1 (Drop categorical variables):\")\n",
        "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSfks8CaXtWs"
      },
      "source": [
        "### Approach 2 - Ordinal Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o-3RAboXbxD"
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "# Make copy to avoid changing original data \n",
        "label_X_train = X_train.copy()\n",
        "label_X_valid = X_valid.copy()\n",
        "\n",
        "# Apply ordinal encoder to each column with categorical data\n",
        "ordinal_encoder = OrdinalEncoder()\n",
        "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
        "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
        "\n",
        "print(\"MAE from Approach 2 (Ordinal Encoding):\") \n",
        "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdf3UhMuXyxk"
      },
      "source": [
        "### Approach 3 - One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFVxQKEgXfPm"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Apply one-hot encoder to each column with categorical data\n",
        "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\n",
        "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))\n",
        "\n",
        "# One-hot encoding removed index; put it back\n",
        "OH_cols_train.index = X_train.index\n",
        "OH_cols_valid.index = X_valid.index\n",
        "\n",
        "# Remove categorical columns (will replace with one-hot encoding)\n",
        "num_X_train = X_train.drop(object_cols, axis=1)\n",
        "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
        "\n",
        "# Add one-hot encoded columns to numerical features\n",
        "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
        "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
        "\n",
        "print(\"MAE from Approach 3 (One-Hot Encoding):\") \n",
        "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b-BylW1jsLO"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKZoIaINZyHj"
      },
      "source": [
        "### Example of Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cgb6xRejnbf"
      },
      "source": [
        "The Concrete dataset contains a variety of concrete formulations and the resulting product's compressive strength, which is a measure of how much load that kind of concrete can bear. The task for this dataset is to predict a concrete's compressive strength given its formulation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vo23GL1GjC3L"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/concrete.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXcKrr8jkH4C"
      },
      "source": [
        "Establishing baselines like this is good practice at the start of the feature engineering process. A baseline score can help you decide whether your new features are worth keeping, or whether you should discard them and possibly try something else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knoQVJCqjVzO"
      },
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"CompressiveStrength\")\n",
        "\n",
        "# Train and score baseline model\n",
        "baseline = RandomForestRegressor(criterion=\"mae\", random_state=0)\n",
        "baseline_score = cross_val_score(\n",
        "    baseline, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
        ")\n",
        "baseline_score = -1 * baseline_score.mean()\n",
        "\n",
        "print(f\"MAE Baseline Score: {baseline_score:.4}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNfJHcwTkiqS"
      },
      "source": [
        "If you ever cook at home, you might know that the ratio of ingredients in a recipe is usually a better predictor of how the recipe turns out than their absolute amounts. We might reason then that ratios of the features above would be a good predictor of CompressiveStrength.\n",
        "\n",
        "The cell below adds three new ratio features to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPMHTnCtjdgg"
      },
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"CompressiveStrength\")\n",
        "\n",
        "# Create synthetic features\n",
        "X[\"FCRatio\"] = X[\"FineAggregate\"] / X[\"CoarseAggregate\"]\n",
        "X[\"AggCmtRatio\"] = (X[\"CoarseAggregate\"] + X[\"FineAggregate\"]) / X[\"Cement\"]\n",
        "X[\"WtrCmtRatio\"] = X[\"Water\"] / X[\"Cement\"]\n",
        "\n",
        "# Train and score model on dataset with additional ratio features\n",
        "model = RandomForestRegressor(criterion=\"mae\", random_state=0)\n",
        "score = cross_val_score(\n",
        "    model, X, y, cv=5, scoring=\"neg_mean_absolute_error\"\n",
        ")\n",
        "score = -1 * score.mean()\n",
        "\n",
        "print(f\"MAE Score with Ratio Features: {score:.4}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrKkKUhopX9Q"
      },
      "source": [
        "### Mutual Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfuzJMCapl4q"
      },
      "source": [
        "The Automobile dataset consists of 193 cars from the 1985 model year. The goal for this dataset is to predict a car's price (the target) from 23 of the car's features, such as make, body_style, and horsepower. In this example, we'll rank the features with mutual information and investigate the results by data visualization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFcW4c5HkUJ8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/autos.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eHvGO8wpqqE"
      },
      "source": [
        "The scikit-learn algorithm for MI treats discrete features differently from continuous features. Consequently, you need to tell it which are which. As a rule of thumb, anything that must have a float dtype is not discrete. Categoricals (object or categorial dtype) can be treated as discrete by giving them a label encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98UE1aHepaeT"
      },
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"price\")\n",
        "\n",
        "# Label encoding for categoricals\n",
        "for colname in X.select_dtypes(\"object\"): X[colname], _ = X[colname].factorize()\n",
        "\n",
        "# All discrete features should now have integer dtypes (double-check this before using MI!)\n",
        "discrete_features = X.dtypes == int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHRyZQa6V0Ms"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNWBiVIMptXz"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "mi_scores = make_mi_scores(X, y, discrete_features)\n",
        "mi_scores[::3]  # show a few features with their MI scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmmhKxu7pvq2"
      },
      "source": [
        "def plot_mi_scores(scores):\n",
        "    scores = scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(scores))\n",
        "    ticks = list(scores.index)\n",
        "    plt.barh(width, scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"Mutual Information Scores\")\n",
        "\n",
        "\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGsQjMmMqRiQ"
      },
      "source": [
        "Data visualization is a great follow-up to a utility ranking. Let's take a closer look at a couple of these.\n",
        "\n",
        "As we might expect, the high-scoring curb_weight feature exhibits a strong relationship with price, the target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtZQJozxqHEI"
      },
      "source": [
        "sns.relplot(x=\"curb_weight\", y=\"price\", data=df);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQDlkBJNqvbC"
      },
      "source": [
        "The fuel_type feature has a fairly low MI score, but as we can see from the figure, it clearly separates two price populations with different trends within the horsepower feature. This indicates that fuel_type contributes an interaction effect and might not be unimportant after all. Before deciding a feature is unimportant from its MI score, it's good to investigate any possible interaction effects -- domain knowledge can offer a lot of guidance here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhqOWjFtqTlR"
      },
      "source": [
        "sns.lmplot(x=\"horsepower\", y=\"price\", hue=\"fuel_type\", data=df);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR8LazqOyQI0"
      },
      "source": [
        "#### Activity: Mutual Information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V_H-bwKz7hl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/ames.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG3tWqge0Dgq"
      },
      "source": [
        "X = df.copy()\n",
        "y = X.pop(\"SalePrice\")\n",
        "\n",
        "# Label encoding for categoricals\n",
        "for colname in X.select_dtypes(\"object\"):\n",
        "    X[colname], _ = X[colname].factorize()\n",
        "\n",
        "# All discrete features should now have integer dtypes (double-check this before using MI!)\n",
        "discrete_features = X.dtypes == int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puCy--JD0NNp"
      },
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "mi_scores = make_mi_scores(X, y, discrete_features)\n",
        "mi_scores[::3]  # show a few features with their MI scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub56co0w0SA2"
      },
      "source": [
        "def plot_mi_scores(scores):\n",
        "    scores = scores.sort_values(ascending=True)\n",
        "    width = np.arange(len(scores))\n",
        "    ticks = list(scores.index)\n",
        "    plt.barh(width, scores)\n",
        "    plt.yticks(width, ticks)\n",
        "    plt.title(\"Mutual Information Scores\")\n",
        "\n",
        "\n",
        "plt.figure(dpi=100, figsize=(8, 5))\n",
        "plot_mi_scores(mi_scores.head(20))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FalvaKHd0zDf"
      },
      "source": [
        "sns.lmplot(x=\"GrLivArea\", y=\"SalePrice\", data=df,hue=\"BldgType\", col=\"BldgType\",scatter_kws={\"edgecolor\": 'w'}, col_wrap=3, height=4);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmGJBks3raih"
      },
      "source": [
        "### Clustering with K-Means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRNgecNwjqgf"
      },
      "source": [
        "#### Simple Demo of K-Means on Iris dataaset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CwgJ3vs1gFZ"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-32zOO0S1lKR"
      },
      "source": [
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ytZ1LM41n1N"
      },
      "source": [
        "features = ['petal length (cm)','petal width (cm)']\n",
        "\n",
        "# Create features matrix\n",
        "x = df.loc[:, features].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE3RgJjo1rWk"
      },
      "source": [
        "y = data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fMHhDoI1vSo"
      },
      "source": [
        "# Apply Standardization to features matrix X\n",
        "x = df.loc[:, features].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vcTLS1D1x5B"
      },
      "source": [
        "x = StandardScaler().fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mqrmg2Z10or"
      },
      "source": [
        "# Plot \n",
        "pd.DataFrame(x, columns = features).plot.scatter('petal length (cm)','petal width (cm)' )\n",
        "\n",
        "# Add labels\n",
        "plt.xlabel('petal length (cm)');\n",
        "plt.ylabel('petal width (cm)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBd5qbG213ky"
      },
      "source": [
        "# Make an instance of KMeans with 3 clusters\n",
        "kmeans = KMeans(n_clusters=3, random_state=1)\n",
        "\n",
        "# Fit only on a features matrix\n",
        "kmeans.fit(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBEfq48O16ye"
      },
      "source": [
        "# Get labels and cluster centroids\n",
        "labels = kmeans.labels_\n",
        "centroids = kmeans.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iAZA6zp19qS"
      },
      "source": [
        "x = pd.DataFrame(x, columns = features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zem9r9112AjZ"
      },
      "source": [
        "colormap = np.array(['r', 'g', 'b'])\n",
        "plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c=colormap[labels])\n",
        "plt.scatter(centroids[:,0], centroids[:,1], s = 300, marker = 'x', c = 'k')\n",
        "\n",
        "plt.xlabel('petal length (cm)')\n",
        "plt.ylabel('petal width (cm)');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygLMSWeO2Do0"
      },
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c=colormap[labels])\n",
        "plt.xlabel('petal length (cm)')\n",
        "plt.ylabel('petal width (cm)');\n",
        "plt.title('K-Means Clustering (k = 3)')\n",
        " \n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x['petal length (cm)'], x['petal width (cm)'], c=colormap[y], s=40)\n",
        "plt.xlabel('petal length (cm)')\n",
        "plt.ylabel('petal width (cm)');\n",
        "plt.title('Flower Species')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHfnnIC01sZ2"
      },
      "source": [
        "#### K-Means Clusters as Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7Lyot6RrdNE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/housing.csv\")\n",
        "X = df.loc[:, [\"MedInc\", \"Latitude\", \"Longitude\"]]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgeo8D9r1QO"
      },
      "source": [
        "# Create cluster feature\n",
        "kmeans = KMeans(n_clusters=6)\n",
        "X[\"Cluster\"] = kmeans.fit_predict(X)\n",
        "X[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n",
        "\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eBNmVeXr35N"
      },
      "source": [
        "sns.relplot(\n",
        "    x=\"Longitude\", y=\"Latitude\", hue=\"Cluster\", data=X, height=6,\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmn5sGFLsDvu"
      },
      "source": [
        "#### Activity: Clustering with K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2ouIrzZsGiV"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Set Matplotlib defaults\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "\n",
        "def score_dataset(X, y, model=XGBRegressor()):\n",
        "    # Label encoding for categoricals\n",
        "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
        "        X[colname], _ = X[colname].factorize()\n",
        "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
        "    score = cross_val_score(\n",
        "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
        "    )\n",
        "    score = -1 * score.mean()\n",
        "    score = np.sqrt(score)\n",
        "    return score\n",
        "\n",
        "\n",
        "# Prepare data\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/ames.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IEy8V9ZhNqL"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mKmF0pyhWi3"
      },
      "source": [
        "X = df.loc[:, [\"LotArea\", \"TotalBsmtSF\", \"FirstFlrSF\", \"SecondFlrSF\",\"GrLivArea\"]]\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P-Zs2Qhg5rg"
      },
      "source": [
        "# Create cluster feature\n",
        "kmeans = KMeans(n_clusters=10)\n",
        "X[\"Cluster\"] = kmeans.fit_predict(X)\n",
        "X[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n",
        "\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIP848SWiZRy"
      },
      "source": [
        "sns.relplot(\n",
        "    x=\"LotArea\", y=\"GrLivArea\", hue=\"Cluster\", data=X, height=6,\n",
        ");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NtaoPsVsZGR"
      },
      "source": [
        "### Principal Component Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ2FjwJq3NgM"
      },
      "source": [
        "#### PCA for Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2N3UN1f2Y3H"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbWjK0BP2b5m"
      },
      "source": [
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "df['target'] = data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F29MY8oB2eUr"
      },
      "source": [
        "speciesDict = {0: 'setosa', 1:'versicolor', 2:'virginica'}\n",
        "\n",
        "df.loc[:,'target'] = df.loc[:, 'target'].apply(lambda x: speciesDict[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYJKadfM2gjI"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9E_0cyw2i9I"
      },
      "source": [
        "# Apply Standardization to features matrix X\n",
        "features = ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)','petal width (cm)']\n",
        "x = df.loc[:, features].values\n",
        "y = df.loc[:,['target']].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGduA4N42l2i"
      },
      "source": [
        "x = StandardScaler().fit_transform(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI5z2Noz2ovG"
      },
      "source": [
        "# Make an instance of PCA\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit and transform the data\n",
        "principalComponents = pca.fit_transform(x)\n",
        "\n",
        "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY4ZOKj32rZL"
      },
      "source": [
        "finalDf = pd.concat([principalDf, df[['target']]], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLNv4nJs2t00"
      },
      "source": [
        "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (8,8));\n",
        "targets = df.loc[:, 'target'].unique()\n",
        "colors = ['r', 'g', 'b']\n",
        "\n",
        "for target, color in zip(targets,colors):\n",
        "    indicesToKeep = finalDf['target'] == target\n",
        "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
        "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
        "               , c = color\n",
        "               , s = 50)\n",
        "\n",
        "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
        "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
        "ax.set_title('2 Component PCA', fontsize = 20)    \n",
        "ax.legend(targets)\n",
        "ax.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gm1Ctre25ou"
      },
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cf1M0vZ2904"
      },
      "source": [
        "sum(pca.explained_variance_ratio_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3v4C_1z3SwU"
      },
      "source": [
        "#### PCA to Speed Up Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHVCOuJd3XQd"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaS1fQBh3b10"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/tertiarycourses/datasets/master/MNISTonly0_1.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl8bo75D3f9i"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DziJsE23kMs"
      },
      "source": [
        "pixel_colnames = df.columns[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRiRWkmi3nLF"
      },
      "source": [
        "# Get all columns except the label column for the first image\n",
        "image_values = df.loc[0, pixel_colnames].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUZKDvYA5F_G"
      },
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "for index in range(0, 2):\n",
        "\n",
        "    plt.subplot(1, 2, 1 + index )\n",
        "    image_values = df.loc[index, pixel_colnames].values\n",
        "    image_label = df.loc[index, 'label']\n",
        "    plt.imshow(image_values.reshape(28,28), cmap ='gray')\n",
        "    plt.title('Label: ' + str(image_label), fontsize = 18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGpnwCwC5JPW"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[pixel_colnames], df['label'], random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eSeZmtd5Mju"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training set only.\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Apply transform to both the training set and the test set.\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLl_3A5W5PH4"
      },
      "source": [
        "# Variable created for demonstational purposes in the notebook\n",
        "scaledTrainImages = X_train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY0qUeyu5Sw3"
      },
      "source": [
        "\"\"\"\n",
        "n_components = .90 means that scikit-learn will choose the minimum number \n",
        "of principal components such that 90% of the variance is retained.\n",
        "\"\"\"\n",
        "\n",
        "pca = PCA(n_components = .90)\n",
        "\n",
        "# Fit PCA on training set only\n",
        "pca.fit(X_train)\n",
        "\n",
        "# Apply the mapping (transform) to both the training set and the test set. \n",
        "X_train = pca.transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "# Logistic Regression\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print('Number of dimensions before PCA: ' + str(len(pixel_colnames)))\n",
        "print('Number of dimensions after PCA: ' + str(pca.n_components_))\n",
        "print('Classification accuracy: ' + str(clf.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCIs8Slw5XSL"
      },
      "source": [
        "# if n_components is not set, all components are kept (784 in this case)\n",
        "pca = PCA()\n",
        "\n",
        "pca.fit(scaledTrainImages)\n",
        "\n",
        "# Summing explained variance\n",
        "tot = sum(pca.explained_variance_)\n",
        "\n",
        "var_exp = [(i/tot)*100 for i in sorted(pca.explained_variance_, reverse=True)] \n",
        "\n",
        "# Cumulative explained variance\n",
        "cum_var_exp = np.cumsum(var_exp)\n",
        "\n",
        "# PLOT OUT THE EXPLAINED VARIANCES SUPERIMPOSED \n",
        "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (10,7));\n",
        "ax.tick_params(labelsize = 18)\n",
        "ax.plot(range(1, 785), cum_var_exp, label='cumulative explained variance')\n",
        "ax.set_ylabel('Cumulative Explained variance', fontsize = 16)\n",
        "ax.set_xlabel('Principal components', fontsize = 16)\n",
        "ax.axhline(y = 95, color='k', linestyle='--', label = '95% Explained Variance')\n",
        "ax.axhline(y = 90, color='c', linestyle='--', label = '90% Explained Variance')\n",
        "ax.axhline(y = 85, color='r', linestyle='--', label = '85% Explained Variance')\n",
        "ax.legend(loc='best', markerscale = 1.0, fontsize = 12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4aRqayO2Zg7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbFe-NoQsat6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "\n",
        "def plot_variance(pca, width=8, dpi=100):\n",
        "    # Create figure\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    n = pca.n_components_\n",
        "    grid = np.arange(1, n + 1)\n",
        "    # Explained variance\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    axs[0].bar(grid, evr)\n",
        "    axs[0].set(\n",
        "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Cumulative Variance\n",
        "    cv = np.cumsum(evr)\n",
        "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
        "    axs[1].set(\n",
        "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Set up figure\n",
        "    fig.set(figwidth=8, dpi=100)\n",
        "    return axs\n",
        "\n",
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/autos.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqnMPvFpstzu"
      },
      "source": [
        "features = [\"highway_mpg\", \"engine_size\", \"horsepower\", \"curb_weight\"]\n",
        "\n",
        "X = df.copy()\n",
        "y = X.pop('price')\n",
        "X = X.loc[:, features]\n",
        "\n",
        "# Standardize\n",
        "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swSAFeVoswux"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create principal components\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Convert to dataframe\n",
        "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
        "\n",
        "X_pca.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDhrdkbnsza-"
      },
      "source": [
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,  # transpose the matrix of loadings\n",
        "    columns=component_names,  # so the columns are the principal components\n",
        "    index=X.columns,  # and the rows are the original features\n",
        ")\n",
        "loadings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTS4jdtUs260"
      },
      "source": [
        "# Look at explained variance\n",
        "plot_variance(pca);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkxbYOI7s5sq"
      },
      "source": [
        "mi_scores = make_mi_scores(X_pca, y, discrete_features=False)\n",
        "mi_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_BhThG4s84-"
      },
      "source": [
        "# Show dataframe sorted by PC3\n",
        "idx = X_pca[\"PC3\"].sort_values(ascending=False).index\n",
        "cols = [\"make\", \"body_style\", \"horsepower\", \"curb_weight\"]\n",
        "df.loc[idx, cols]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOlYZbLWs_m4"
      },
      "source": [
        "df[\"sports_or_wagon\"] = X.curb_weight / X.horsepower\n",
        "sns.regplot(x=\"sports_or_wagon\", y='price', data=df, order=2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgUKi5SmtHKx"
      },
      "source": [
        "#### PCA For Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxyJPPfKsSsY"
      },
      "source": [
        "In this example, we'll return to our Automobile dataset and apply PCA, using it as a descriptive technique to discover features. We'll look at other use-cases in the exercise.\n",
        "\n",
        "This hidden cell loads the data and defines the functions plot_variance and make_mi_scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I1AUDyXr7Nf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "\n",
        "def plot_variance(pca, width=8, dpi=100):\n",
        "    # Create figure\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    n = pca.n_components_\n",
        "    grid = np.arange(1, n + 1)\n",
        "    # Explained variance\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    axs[0].bar(grid, evr)\n",
        "    axs[0].set(\n",
        "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Cumulative Variance\n",
        "    cv = np.cumsum(evr)\n",
        "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
        "    axs[1].set(\n",
        "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Set up figure\n",
        "    fig.set(figwidth=8, dpi=100)\n",
        "    return axs\n",
        "\n",
        "def make_mi_scores(X, y, discrete_features):\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/autos.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSW0kcb5sWUV"
      },
      "source": [
        "We've selected four features that cover a range of properties. Each of these features also has a high MI score with the target, price. We'll standardize the data since these features aren't naturally on the same scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GZa8eU3sFBy"
      },
      "source": [
        "features = [\"highway_mpg\", \"engine_size\", \"horsepower\", \"curb_weight\"]\n",
        "\n",
        "X = df.copy()\n",
        "y = X.pop('price')\n",
        "X = X.loc[:, features]\n",
        "\n",
        "# Standardize\n",
        "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTCT0uWksY5n"
      },
      "source": [
        "Now we can fit scikit-learn's PCA estimator and create the principal components. You can see here the first few rows of the transformed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oghGC4AlsHmJ"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create principal components\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Convert to dataframe\n",
        "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
        "\n",
        "X_pca.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWe7SP_7scgY"
      },
      "source": [
        "After fitting, the PCA instance contains the loadings in its components_ attribute. (Terminology for PCA is inconsistent, unfortunately. We're following the convention that calls the transformed columns in X_pca the components, which otherwise don't have a name.) We'll wrap the loadings up in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJnmqVFksKcO"
      },
      "source": [
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,  # transpose the matrix of loadings\n",
        "    columns=component_names,  # so the columns are the principal components\n",
        "    index=X.columns,  # and the rows are the original features\n",
        ")\n",
        "loadings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1wlimJLsf1A"
      },
      "source": [
        "Recall that the signs and magnitudes of a component's loadings tell us what kind of variation it's captured. The first component (PC1) shows a contrast between large, powerful vehicles with poor gas milage, and smaller, more economical vehicles with good gas milage. We might call this the \"Luxury/Economy\" axis. The next figure shows that our four chosen features mostly vary along the Luxury/Economy axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1mtQvVtsNqN"
      },
      "source": [
        "# Look at explained variance\n",
        "plot_variance(pca);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGewKj3EsjDL"
      },
      "source": [
        "Let's also look at the MI scores of the components. Not surprisingly, PC1 is highly informative, though the remaining components, despite their small variance, still have a significant relationship with price. Examining those components could be worthwhile to find relationships not captured by the main Luxury/Economy axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WswQB48fsmrT"
      },
      "source": [
        "mi_scores = make_mi_scores(X_pca, y, discrete_features=False)\n",
        "mi_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzQ5IohMsv-d"
      },
      "source": [
        "df[\"sports_or_wagon\"] = X.curb_weight / X.horsepower\n",
        "sns.regplot(x=\"sports_or_wagon\", y='price', data=df, order=2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsuKONMaszKs"
      },
      "source": [
        "To express this contrast, let's create a new ratio feature:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqxjtHgDsyKu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QoPUk0QtIlr"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Set Matplotlib defaults\n",
        "plt.style.use(\"seaborn-whitegrid\")\n",
        "plt.rc(\"figure\", autolayout=True)\n",
        "plt.rc(\n",
        "    \"axes\",\n",
        "    labelweight=\"bold\",\n",
        "    labelsize=\"large\",\n",
        "    titleweight=\"bold\",\n",
        "    titlesize=14,\n",
        "    titlepad=10,\n",
        ")\n",
        "\n",
        "\n",
        "def apply_pca(X, standardize=True):\n",
        "    # Standardize\n",
        "    if standardize:\n",
        "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "    # Create principal components\n",
        "    pca = PCA()\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    # Convert to dataframe\n",
        "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "    X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
        "    # Create loadings\n",
        "    loadings = pd.DataFrame(\n",
        "        pca.components_.T,  # transpose the matrix of loadings\n",
        "        columns=component_names,  # so the columns are the principal components\n",
        "        index=X.columns,  # and the rows are the original features\n",
        "    )\n",
        "    return pca, X_pca, loadings\n",
        "\n",
        "\n",
        "def plot_variance(pca, width=8, dpi=100):\n",
        "    # Create figure\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    n = pca.n_components_\n",
        "    grid = np.arange(1, n + 1)\n",
        "    # Explained variance\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    axs[0].bar(grid, evr)\n",
        "    axs[0].set(\n",
        "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Cumulative Variance\n",
        "    cv = np.cumsum(evr)\n",
        "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
        "    axs[1].set(\n",
        "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    # Set up figure\n",
        "    fig.set(figwidth=8, dpi=100)\n",
        "    return axs\n",
        "\n",
        "\n",
        "def make_mi_scores(X, y):\n",
        "    X = X.copy()\n",
        "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
        "        X[colname], _ = X[colname].factorize()\n",
        "    # All discrete features should now have integer dtypes\n",
        "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
        "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "\n",
        "def score_dataset(X, y, model=XGBRegressor()):\n",
        "    # Label encoding for categoricals\n",
        "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
        "        X[colname], _ = X[colname].factorize()\n",
        "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
        "    score = cross_val_score(\n",
        "        model, X, y, cv=5, scoring=\"neg_mean_squared_log_error\",\n",
        "    )\n",
        "    score = -1 * score.mean()\n",
        "    score = np.sqrt(score)\n",
        "    return score\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/tertiarycourses/datasets/master/ames.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS372_85tf3m"
      },
      "source": [
        "features = [\n",
        "    \"GarageArea\",\n",
        "    \"YearRemodAdd\",\n",
        "    \"TotalBsmtSF\",\n",
        "    \"GrLivArea\",\n",
        "]\n",
        "\n",
        "print(\"Correlation with SalePrice:\\n\")\n",
        "print(df[features].corrwith(df.SalePrice))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2ljhktvuPkN"
      },
      "source": [
        "features = [\n",
        "    \"GarageArea\",\n",
        "    \"YearRemodAdd\",\n",
        "    \"TotalBsmtSF\",\n",
        "    \"GrLivArea\",\n",
        "]\n",
        "X = df.copy()\n",
        "y = X.pop(\"SalePrice\")\n",
        "X = X.loc[:, features]\n",
        "\n",
        "# Standardize\n",
        "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ts7WgSQrlwP"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create principal components\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Convert to dataframe\n",
        "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
        "\n",
        "X_pca.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DYSh4KIrozm"
      },
      "source": [
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,  # transpose the matrix of loadings\n",
        "    columns=component_names,  # so the columns are the principal components\n",
        "    index=X.columns,  # and the rows are the original features\n",
        ")\n",
        "loadings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JfX1Rt_u0na"
      },
      "source": [
        "# Look at explained variance\n",
        "plot_variance(pca);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rZu-r1XeEbj"
      },
      "source": [
        "## Text Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5vrjml0gUkk"
      },
      "source": [
        "### Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWCITWcReDs8"
      },
      "source": [
        "corpus = [\n",
        "'It was the best of times',\n",
        "'It was the worst of times',\n",
        "'It was the age of wisdom',\n",
        "'It was the age of foolishness and age of wisdom'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tCoE6QbgQeS"
      },
      "source": [
        "### Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "504KTvooeQJ3"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(corpus)\n",
        "\n",
        "print(cv.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ufh2g-HimJK"
      },
      "source": [
        "### N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyC9uCuygXxN"
      },
      "source": [
        "cv = CountVectorizer(ngram_range=(1, 2))\n",
        "X = cv.fit_transform(corpus)\n",
        "print(cv.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9f8oDzMiq78"
      },
      "source": [
        "### TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeCd5xk2hgWs"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4bAw82miuz4"
      },
      "source": [
        "### Hash Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfLg78LyiLYY"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "vectorizer = HashingVectorizer(n_features=7)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_HtMi4FiwoJ"
      },
      "source": [
        "### Activity: Text Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uQtk0XuikY6"
      },
      "source": [
        "corpus = [\n",
        "'This is the first document.',\n",
        "'This document is the second document.',\n",
        "'And this is the third one.',\n",
        "'Is this the first document?',\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3gDJDMFj2b-"
      },
      "source": [
        "#### Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwQeDNDui2oz"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(corpus)\n",
        "\n",
        "print(cv.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYWExUK6j5f3"
      },
      "source": [
        "#### N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yep6S_rkjsh5"
      },
      "source": [
        "cv = CountVectorizer(ngram_range=(1, 2))\n",
        "X = cv.fit_transform(corpus)\n",
        "print(cv.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Of4h2CRKj8mk"
      },
      "source": [
        "#### TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lkbCLG3jwLt"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(vectorizer.get_feature_names())\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp9gZrZ0j_0C"
      },
      "source": [
        "#### Hash Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV59jZ8vjyds"
      },
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "vectorizer = HashingVectorizer(n_features=7)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBF7lVxep4VD"
      },
      "source": [
        "# Topic 2 Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbCL7QIw0Dcs"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flkas9sr0Sti"
      },
      "source": [
        "## ML Flow without Using Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvzWir5F0IdI"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_std = scaler.transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "clf = SVC().fit(X_train_std, y_train)\n",
        "clf.score(X_test_std, y_test)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqRXy5Mp0VzV"
      },
      "source": [
        "## ML Flow  Using Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHliU8KT0rqK"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = Pipeline([('scaler', StandardScaler()), ('svc', SVC())]).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrgQ9muh0kso"
      },
      "source": [
        "## Chain Multiple Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQVbeBJe0NkX"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "preprocessor = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "clf = Pipeline([('preprocessor', preprocessor), ('svc', SVC())]).fit(X_train, y_train)\n",
        "clf.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKg4QkQ52AFo"
      },
      "source": [
        "## Applications of Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZvNCSXi2OY_"
      },
      "source": [
        "### Evaluate Multiple Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tAM_xHe2Sux"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(3),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    LogisticRegression(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier()\n",
        "    ]\n",
        "\n",
        "for classifier in classifiers:\n",
        "    pipe = Pipeline([('preprocessor', preprocessor),\n",
        "                      ('classifier', classifier)])\n",
        "    pipe.fit(X_train, y_train)   \n",
        "    print(classifier)\n",
        "    print(\"model score: %.3f\" % pipe.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JEOuiXw2qi4"
      },
      "source": [
        "### Sentimental Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_0MqXRI2uRU"
      },
      "source": [
        "import pandas as pd\n",
        "training = pd.DataFrame([\n",
        "    (0, \"This movie is nice\", 1.0),\n",
        "    (1, \"The plot is bad\", 0.0),\n",
        "    (2, \"The actors are excellent\", 1.0),\n",
        "    (3, \"The acting is lousy\", 0.0),\n",
        "    (4, \"The plot is good\", 1.0),\n",
        "    (5, \"plot is good\", 1.0),\n",
        "    (6, \"The actors are bad\", 0.0)\n",
        "], columns= [\"id\", \"text\", \"label\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOq-TqZA2waL"
      },
      "source": [
        "X_train = training.text.values\n",
        "y_train = training.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnLHp_gf2yt3"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipe = Pipeline([('hv', HashingVectorizer()),('clf', LogisticRegression())])\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcYiKExi21ZK"
      },
      "source": [
        "X_test = ['the actors are good']\n",
        "pipe.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-K0ZUXhv3q2-"
      },
      "source": [
        "### Activity: Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk_9wiwPp6Y_"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv')\n",
        "\n",
        "# Separate target from predictors\n",
        "y = data.Price\n",
        "X = data.drop(['Price'], axis=1)\n",
        "\n",
        "# Divide data into training and validation subsets\n",
        "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
        "                                                                random_state=0)\n",
        "\n",
        "# \"Cardinality\" means the number of unique values in a column\n",
        "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
        "categorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
        "                        X_train_full[cname].dtype == \"object\"]\n",
        "\n",
        "# Select numerical columns\n",
        "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\n",
        "\n",
        "# Keep selected columns only\n",
        "my_cols = categorical_cols + numerical_cols\n",
        "X_train = X_train_full[my_cols].copy()\n",
        "X_valid = X_valid_full[my_cols].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0INkj2lqDzd"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoNpsYO034Bz"
      },
      "source": [
        "We construct the full pipeline in three steps.\n",
        "\n",
        "#### Step 1: Define Preprocessing Steps\n",
        "Similar to how a pipeline bundles together preprocessing and modeling steps, we use the ColumnTransformer class to bundle together different preprocessing steps. The code below:\n",
        "\n",
        "- imputes missing values in numerical data, and\n",
        "- imputes missing values and applies a one-hot encoding to categorical data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Bqo27MqGwy"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = SimpleImputer(strategy='constant')\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUaV_98l4Hi0"
      },
      "source": [
        "#### Step 2: Define the Model\n",
        "Next, we define a random forest model with the familiar RandomForestRegressor class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE6BYhkhqKxF"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozjwwOvu4Nu-"
      },
      "source": [
        "#### Step 3: Create and Evaluate the Pipeline\n",
        "Finally, we use the Pipeline class to define a pipeline that bundles the preprocessing and modeling steps. There are a few important things to notice:\n",
        "\n",
        "With the pipeline, we preprocess the training data and fit the model in a single line of code. (In contrast, without a pipeline, we have to do imputation, one-hot encoding, and model training in separate steps. This becomes especially messy if we have to deal with both numerical and categorical variables!)\n",
        "With the pipeline, we supply the unprocessed features in X_valid to the predict() command, and the pipeline automatically preprocesses the features before generating predictions. (However, without a pipeline, we have to remember to preprocess the validation data before making predictions.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XelIgIdmqNiq"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Bundle preprocessing and modeling code in a pipeline\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                              ('model', model)\n",
        "                             ])\n",
        "\n",
        "# Preprocessing of training data, fit model \n",
        "my_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Preprocessing of validation data, get predictions\n",
        "preds = my_pipeline.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "score = mean_absolute_error(y_valid, preds)\n",
        "print('MAE:', score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zd2ahdRqYtC"
      },
      "source": [
        "# Topic 3 Cross Validation & Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpGVHwe9DmBW"
      },
      "source": [
        "## Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBL3CodUCSD7"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3FyEaK0CcmS"
      },
      "source": [
        "clf = SVC(kernel='linear').fit(X_train, y_train)\n",
        "scores = clf.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnzncuWZCijB"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
        "scores.mean(), scores.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbBpfSwn7tFa"
      },
      "source": [
        "### Activity: Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPD9nCYdqatD"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv')\n",
        "\n",
        "# Select subset of predictors\n",
        "cols_to_use = ['Rooms', 'Distance', 'Landsize', 'BuildingArea', 'YearBuilt']\n",
        "X = data[cols_to_use]\n",
        "\n",
        "# Select target\n",
        "y = data.Price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-lmIbPzEy6Q"
      },
      "source": [
        "Then, we define a pipeline that uses an imputer to fill in missing values and a random forest model to make predictions.\n",
        "\n",
        "While it's possible to do cross-validation without pipelines, it is quite difficult! Using a pipeline will make the code remarkably straightforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYVwZ8v_qh1U"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "my_pipeline = Pipeline(steps=[('preprocessor', SimpleImputer()),\n",
        "                              ('model', RandomForestRegressor(n_estimators=50,\n",
        "                                                              random_state=0))\n",
        "                             ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtryuvVfE2F9"
      },
      "source": [
        "We obtain the cross-validation scores with the cross_val_score() function from scikit-learn. We set the number of folds with the cv paramete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0C0ffBdqkAD"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Multiply by -1 since sklearn calculates *negative* MAE\n",
        "scores = -1 * cross_val_score(my_pipeline, X, y,cv=5, scoring='neg_mean_absolute_error')\n",
        "\n",
        "print(\"MAE scores:\\n\", scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0PvU3b_E7Oa"
      },
      "source": [
        "The  scoring parameter chooses a measure of model quality to report: in this case, we chose negative mean absolute error (MAE).\n",
        "\n",
        "It is a little surprising that we specify negative MAE. Scikit-learn has a convention where all metrics are defined so a high number is better. Using negatives here allows them to be consistent with that convention, though negative MAE is almost unheard of elsewhere.\n",
        "\n",
        "We typically want a single measure of model quality to compare alternative models. So we take the average across experiments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1bWMMP2ql24"
      },
      "source": [
        "print(\"Average MAE score (across experiments):\")\n",
        "print(scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWtszplD_AAC"
      },
      "source": [
        "## GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEm_d9Zf-saL"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BirWYpMLlXi"
      },
      "source": [
        "### SVC using default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZOtpNop-vSZ"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "\n",
        "svc.fit(X_train,y_train)\n",
        "scores = svc.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EEHnZELLrQX"
      },
      "source": [
        "### GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCx_6rgZ-30Q"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [{'kernel':['linear', 'rbf'], 'C':[1, 10, 100, 1000]}]\n",
        "search = GridSearchCV(svc, param_grid, cv=5).fit(X_train,y_train)\n",
        "\n",
        "print(search.best_params_)    \n",
        "print(search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENCSKhaiMp4e"
      },
      "source": [
        "### Try out the Best Parameters for SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9W7kYOw-6r9"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(C=1, kernel='linear')\n",
        "\n",
        "svc.fit(X_train,y_train)\n",
        "scores = svc.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbef2j4aGflA"
      },
      "source": [
        "### Activity: GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFeVnSeCGmQw"
      },
      "source": [
        "import pandas as pd\n",
        "    \n",
        "# Load data\n",
        "melbourne_file_path = 'https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv'\n",
        "melbourne_data = pd.read_csv(melbourne_file_path) \n",
        "# Filter rows with missing values\n",
        "melbourne_data = melbourne_data.dropna(axis=0)\n",
        "# Choose target and features\n",
        "y = melbourne_data.Price\n",
        "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n",
        "X = melbourne_data[melbourne_features]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKzmdnKP-faR"
      },
      "source": [
        "#### Using Default Parameters for KNN Neighbour Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2UiDK6pHPLR"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "scores = knn.score(X_test, y_test) \n",
        "scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-dzEw3d-tyU"
      },
      "source": [
        "#### Perform GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bWcSUR-HRQm"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "knn_pipe = Pipeline([('mms', MinMaxScaler()),('knn', KNeighborsClassifier())])\n",
        "\n",
        "param_grid = [{'knn__n_neighbors': [3, 5, 7, 9],'knn__weights': ['uniform', 'distance'],'knn__leaf_size': [15, 20]}]\n",
        "\n",
        "search = GridSearchCV(knn_pipe,param_grid, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print(search.best_params_)    \n",
        "print(search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhdUBAZ4-0s9"
      },
      "source": [
        "### Using Optimal Parameters for KNN Neighbour Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIixXqs2HUEx"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "knn = KNeighborsClassifier(leaf_size=15, n_neighbors=9,weights='distance')\n",
        "knn.fit(X_train, y_train)\n",
        "scores = knn.score(X_test, y_test) \n",
        "scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3q0N-BP_Gks"
      },
      "source": [
        "## RandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_DjHfB_T98W"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCUETIGWVJms"
      },
      "source": [
        "### SVC using default parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SqGWg7VUDod"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "\n",
        "svc.fit(X_train,y_train)\n",
        "scores = svc.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bV84fqQVN9V"
      },
      "source": [
        "### RandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paxcysDY_Jk7"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "\n",
        "param_grid = [{'kernel':['linear', 'rbf'], 'C':[1, 10, 100, 1000]}]\n",
        "search = RandomizedSearchCV(svc, param_grid, cv=5).fit(X_train,y_train)\n",
        "\n",
        "print(search.best_params_)    \n",
        "print(search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2kWKwWRVUbQ"
      },
      "source": [
        "### Try out the Best Parameters for SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfpBWiEDUSnX"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC(C=1, kernel='linear')\n",
        "\n",
        "svc.fit(X_train,y_train)\n",
        "scores = svc.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDKf2PkSVa4v"
      },
      "source": [
        "### Activity: RandomSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgmTL9ii_Pob"
      },
      "source": [
        "import pandas as pd\n",
        "    \n",
        "# Load data\n",
        "melbourne_file_path = 'https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv'\n",
        "melbourne_data = pd.read_csv(melbourne_file_path) \n",
        "# Filter rows with missing values\n",
        "melbourne_data = melbourne_data.dropna(axis=0)\n",
        "# Choose target and features\n",
        "y = melbourne_data.Price\n",
        "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n",
        "X = melbourne_data[melbourne_features]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDVg3_S8_Sag"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "scores = knn.score(X_test, y_test) \n",
        "scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXsHwT10_VDi"
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "knn_pipe = Pipeline([('mms', MinMaxScaler()),('knn', KNeighborsClassifier())])\n",
        "\n",
        "param_grid = [{'knn__n_neighbors': [3, 5, 7, 9],'knn__weights': ['uniform', 'distance'],'knn__leaf_size': [15, 20]}]\n",
        "\n",
        "search = RandomizedSearchCV(knn_pipe,param_grid, cv=5).fit(X_train, y_train)\n",
        "\n",
        "print(search.best_params_)    \n",
        "print(search.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ep3kAl0xWFbf"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "knn = KNeighborsClassifier(leaf_size=20, n_neighbors=9,weights='distance')\n",
        "knn.fit(X_train, y_train)\n",
        "scores = knn.score(X_test, y_test) \n",
        "scores\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBLPlmydquhz"
      },
      "source": [
        "# Topic 4 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfN4_tOObXf0"
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X,y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HotZDGa8be5k"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "model = XGBRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "scores = model.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaAV-S3MbhRI"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uukXuvfyqv2F"
      },
      "source": [
        "import pandas as pd\n",
        "    \n",
        "# Load data\n",
        "melbourne_file_path = 'https://raw.githubusercontent.com/tertiarycourses/datasets/master/melb_data.csv'\n",
        "melbourne_data = pd.read_csv(melbourne_file_path) \n",
        "# Filter rows with missing values\n",
        "melbourne_data = melbourne_data.dropna(axis=0)\n",
        "# Choose target and features\n",
        "y = melbourne_data.Price\n",
        "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude']\n",
        "X = melbourne_data[melbourne_features]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ7M4c6JZ2za"
      },
      "source": [
        "In this example, you'll work with the XGBoost library. XGBoost stands for extreme gradient boosting, which is an implementation of gradient boosting with several additional features focused on performance and spee"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acYPgvfcZyso"
      },
      "source": [
        "We also make predictions and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QL0zuOzqy44"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "\n",
        "model = XGBRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "scores = model.score(X_test, y_test) \n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY3oYpuOq5P8"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "print(\"Mean Absolute Error: \" + str(mean_absolute_error(predictions, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjwTXiJEbyJh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}